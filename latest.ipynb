{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping install as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: llama-hub 0.0.79.post1\n",
      "Uninstalling llama-hub-0.0.79.post1:\n",
      "  Would remove:\n",
      "    /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/LICENSE\n",
      "    /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/llama_hub-0.0.79.post1.dist-info/*\n",
      "    /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/llama_hub/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_hub llama-index llama-index-core llama-index-retrievers-bm25 llama-index-llms-ollama pydantic transformers llama-index-llms-openai llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Setup paths to user guide file and folder to store the created chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_PATH = './output_text_file.txt'\n",
    "FIXED_CHUNK_FOLDER = './chunkraw/fixed_size'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup llm and embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled 23 dropout modules from model type <class 'transformers_modules.jxm.cde-small-v2.287bf0ea6ebfecf2339762d0ef28fb846959a8f2.model.BiEncoder'>\n",
      "Disabled 46 dropout modules from model type <class 'transformers_modules.jxm.cde-small-v2.287bf0ea6ebfecf2339762d0ef28fb846959a8f2.model.ContextualDocumentEmbeddingTransformer'>\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "#llm = Ollama(model=\"llama3.1:8B\", temperature=0.1,request_timeout=300)\n",
    "llm = OpenAI(model=\"gpt-4o-mini\",temperature= 0.1, api_key=\"api key\")\n",
    "#embeddings = HuggingFaceEmbedding(model_name=\"all-MiniLM-L6-v2\")\n",
    "embeddings = HuggingFaceEmbedding(model_name=\"jxm/cde-small-v2\",trust_remote_code=True,max_length=768)\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and chunk it into fixed sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "def fixed_size_chunking(doc_text: str, chunk_size: int, overlap: int) -> List[str]:\n",
    "    words = doc_text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def save_chunks(chunks: List[str], folder_name: str):\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(os.path.join(folder_name, f\"chunk_{i + 1}.txt\"), 'w', encoding='utf-8') as f:\n",
    "            f.write(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process text file and create nodes, this including the method of actually splitting the documents, currently using sentencesplitter with overlapping as the base method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter, SemanticSplitterNodeParser\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "def process_text_file(data_file=DATA_FILE_PATH, chunk_size=250, overlap=50):\n",
    "    start_time = time.process_time()\n",
    "    print(\"Starting chunking process...\")\n",
    "    try:\n",
    "        load_start_time = time.process_time()\n",
    "        if os.path.exists(FIXED_CHUNK_FOLDER) and os.listdir(FIXED_CHUNK_FOLDER):\n",
    "            print(\"Loading existing chunks...\")\n",
    "            documents = [Document(text=open(f.path, 'r').read()) for f in os.scandir(FIXED_CHUNK_FOLDER) if f.is_file()]\n",
    "        else:\n",
    "            with open(data_file, 'r', encoding='utf-8') as file:\n",
    "                doc_text = file.read()\n",
    "\n",
    "            if not doc_text:\n",
    "                raise ValueError(\"No content found in the specified text file.\")\n",
    "\n",
    "            print(\"Chunking the text...\")\n",
    "            chunk_start_time = time.process_time()\n",
    "            chunks = fixed_size_chunking(doc_text, chunk_size, overlap)\n",
    "            chunk_end_time = time.process_time()\n",
    "            \n",
    "            save_start_time = time.process_time()\n",
    "            save_chunks(chunks, FIXED_CHUNK_FOLDER)\n",
    "            save_end_time = time.process_time()\n",
    "            \n",
    "            print(f\"Chunking completed in {chunk_end_time - chunk_start_time:.2f} seconds.\")\n",
    "            print(f\"Chunks saved in {save_end_time - save_start_time:.2f} seconds.\")\n",
    "            \n",
    "            documents = [Document(text=open(f.path, 'r').read()) for f in os.scandir(FIXED_CHUNK_FOLDER) if f.is_file()]\n",
    "\n",
    "\n",
    "        #Sentence splitter\n",
    "        splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "        nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "        #Semantic splitter\n",
    "        # splitter = SemanticSplitterNodeParser(buffer_size=1, breakpoint_percentile_threshold=95, embed_model= Settings.embed_model)\n",
    "        # nodes = splitter.get_nodes_from_documents(documents)\n",
    "        print(\"Processing completed successfully.\")\n",
    "        return nodes\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text file: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the nodes (splitted documents), customising the indexes, retrievers, queriers and chat engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import ReActAgent, FunctionCallingAgent\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.response_synthesizers import TreeSummarize\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.chat_engine import ContextChatEngine\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
    "def creating_agent(nodes):\n",
    "    bm25_retriever = BM25Retriever.from_defaults(\n",
    "        nodes=nodes,\n",
    "        similarity_top_k=10,\n",
    "        language=\"english\",\n",
    "        \n",
    "    )\n",
    "\n",
    "    response_synthesizer = get_response_synthesizer(response_mode=\"tree_summarize\")\n",
    "    #response_synthesizer = summarizer\n",
    "    query_engine = RetrieverQueryEngine(\n",
    "        retriever = bm25_retriever,\n",
    "        response_synthesizer=response_synthesizer,\n",
    "        node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    "    )\n",
    "\n",
    "    index_configs = []\n",
    "\n",
    "    RAG_tool = QueryEngineTool(\n",
    "        query_engine = query_engine,\n",
    "        metadata=ToolMetadata(name = f\"vector\", description=f\"useful for when you want to asnwer queries about the Equix documents\"),\n",
    "    )\n",
    "\n",
    "    index_configs.append(RAG_tool)\n",
    "\n",
    "    summary_index = SummaryIndex(nodes,show_progress=True)\n",
    "    summary_query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\",use_async=True,)\n",
    "    summary_tool = QueryEngineTool.from_defaults(\n",
    "        name=\"summary\",\n",
    "        query_engine=summary_query_engine,\n",
    "        description=(\n",
    "            \"Useful if you want to get a summary of Equix documents\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    index_configs.append(summary_tool)\n",
    "    context = \"If the user asks a question the you already know the answer to OR the user is making idle banter, just respond without calling any tools.\"\n",
    "    #agent = ReActAgent.from_tools(index_configs,llm = Settings.llm, verbose=True, memory= ChatMemoryBuffer(token_limit=3900))\n",
    "    #React_agent = ReActAgent.from_tools(index_configs,llm = Settings.llm, verbose=True,context= context,max_iterations=10)\n",
    "    memory = ChatMemoryBuffer.from_defaults(token_limit=1500)\n",
    "    custom_prompt = PromptTemplate(\n",
    "    \"\"\"\\\n",
    "    Given a conversation (between Human and Assistant) and a follow up message from Human, \\\n",
    "    rewrite the message to be a standalone question that captures all relevant context \\\n",
    "    from the conversation.\n",
    "\n",
    "    <Chat History>\n",
    "    {chat_history}\n",
    "\n",
    "    <Follow Up Message>\n",
    "    {question}\n",
    "\n",
    "    <Standalone question>\n",
    "    \"\"\"\n",
    "    )\n",
    "    \n",
    "    CONTEXT_PROMPT_TEMPLATE = \"\"\"\n",
    "  The following is a friendly conversation between a user and an AI assistant.\n",
    "  The assistant is talkative and provides lots of specific details from its context.\n",
    "  If the assistant does not know the answer to a question, it truthfully says it\n",
    "  does not know without being hallucinated.\n",
    "\n",
    "  Here are the relevant documents for the context:\n",
    "\n",
    "  {context_str}\n",
    "\n",
    "  Instruction: Based on the above documents, provide a detailed answer for the user question below. Never mention about the source of context or documents. Try to be as much humane as possible.\n",
    "  Answer \"don't know, please provide more information\" if not present in the document.\n",
    "  \"\"\"\n",
    "    CONTEXT_REFINE_PROMPT_TEMPLATE = \"\"\"\n",
    "  The following is a friendly conversation between a user and an AI assistant.\n",
    "  The assistant is talkative and provides lots of specific details from its context.\n",
    "  If the assistant does not know the answer to a question, it truthfully says it\n",
    "  does not know.\n",
    "\n",
    "  Here are the relevant documents for the context:\n",
    "\n",
    "  {context_msg}\n",
    "\n",
    "  Existing Answer:\n",
    "  {existing_answer}\n",
    "\n",
    "  Instruction: Refine the existing answer using the provided context to assist the user. Never mention about the source of context or documents. Try to be as much humane as possible.\n",
    "  If the context isn't helpful, just repeat the existing answer and nothing more. Never mention about the source of context or documents. Try to be as much humane as possible.\n",
    "  \"\"\"\n",
    "    CONDENSE_PROMPT_TEMPLATE = \"\"\"\n",
    "  Given the following conversation between a user and an AI assistant and a follow up question from user,\n",
    "  rephrase the follow up question to be a standalone question.\n",
    "\n",
    "  Chat History:\n",
    "  {chat_history}\n",
    "  Follow Up Input: {question}\n",
    "  Standalone question:\"\"\"\n",
    "    sys_prompt = \"\"\"\n",
    "    You are a truthful AI that sticks to the instruction.\n",
    "\n",
    "    Instruction: use the provided context to answer the question from the users. If the answer is not provided in the context, please don't imaginatively generate random response. Never mention about the source of the contex or information. You MUST try to be as much humane as possible\n",
    "    \"\"\"\n",
    "    React_agent = CondensePlusContextChatEngine(\n",
    "        retriever=bm25_retriever, \n",
    "        llm = Settings.llm, \n",
    "        memory=memory, \n",
    "        system_prompt=sys_prompt, \n",
    "        context_prompt= CONTEXT_PROMPT_TEMPLATE, \n",
    "        context_refine_prompt=CONTEXT_REFINE_PROMPT_TEMPLATE, \n",
    "        condense_prompt= CONDENSE_PROMPT_TEMPLATE,\n",
    "        node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    "        verbose=True\n",
    "    )\n",
    "    func_agent = FunctionCallingAgentWorker.from_tools(index_configs,llm = Settings.llm, verbose= True)\n",
    "    func_agent = AgentRunner(func_agent)\n",
    "    #zilliz = creating_zillis_index(nodes=nodes, pipeline_ids=pipeline_ids)\n",
    "    #index = VectorStoreIndex.build_index_from_nodes(nodes= nodes)\n",
    "    #engine = index.as_chat_engine(chat_mode = \"best\", llm = Settings.llm, verbose = True )\n",
    "    return bm25_retriever, query_engine,React_agent,func_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index(chunk_size=100, overlap=10):\n",
    "    nodes = process_text_file(chunk_size=chunk_size, overlap=overlap)\n",
    "    return creating_agent(nodes=nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data source, create chunks and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chunking process...\n",
      "Loading existing chunks...\n",
      "Processing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE_PATH = './output_text_file.txt'\n",
    "FIXED_CHUNK_FOLDER = './chunkraw/fixed_size'\n",
    "#customise the chunk size: too high will lead to ambiguity in the retrieval: the gathered data is too general and hence, too long to compute. too low will lead to missing of data\n",
    "chunk_size = 100\n",
    "overlap = 10\n",
    "\n",
    "retriever,query_engine,chat_agent,func_agent = load_index(chunk_size=chunk_size, overlap=overlap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test retriever, querier, chat engine and function calling agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condensed question: how do I place an order?\n",
      "Retrieved nodes from the index:\n",
      "retriever: Node ID: 3b884962-a89f-413b-bf4f-67efc63c0e2f\n",
      "Text: applied for Equity only. = Placed Price * Placed Quantity + Fees\n",
      "Open Orders (Sells) The total value of sell orders that are still\n",
      "working (open). Currently applied for Equity only. = Placed Price *\n",
      "Placed Quantity - Fees Trading Balance The available balance that you\n",
      "can place order Trading balance = Cash at bank+ Transaction not booked\n",
      "Value o...\n",
      "Score:  2.515\n",
      "\n",
      "retriever: Node ID: d27610b7-2ef1-4559-b4a5-16c089a68903\n",
      "Text: provide the status of the profit of the company Profit Margin\n",
      "The portion of a company’s sales revenue that it gets to keep as a\n",
      "profit, after subtracting all its costs Operating Margin Measures how\n",
      "much profit a company makes on a dollar of sales after paying for\n",
      "variable costs of production Management Effectiveness Return on Assets\n",
      "The financi...\n",
      "Score:  2.310\n",
      "\n",
      "retriever: Node ID: 7d529d11-215c-4499-90c2-ec678b1e6099\n",
      "Text: Trading IV.1. New order Place an Order in the Quick Order Pad\n",
      "Step 1. Open the widget: Select Menu -> New Order or: Select Menu ->\n",
      "Trading ->\n",
      "Score:  2.303\n",
      "\n",
      "retriever: Node ID: f3ca582d-ca63-4a99-a67a-3ac0af8d5d8a\n",
      "Text: Currently applied for Equity only. -- Others Transactions\n",
      "pending due for more than 3 business days. Currently applied for\n",
      "Equity only. -- Open Orders (Buys) The total value of buy orders that\n",
      "are still working (open). Currently applied for Equity only. = Placed\n",
      "Price * Placed Quantity\n",
      "Score:  2.166\n",
      "\n",
      "retriever: Node ID: 855067b7-1142-43cd-ba75-beca91b1a8a1\n",
      "Text: • Allow integer Value Input the value of the order that you want\n",
      "to place Display if Purchase By = Value Limit\n",
      "Score:  2.091\n",
      "\n",
      "retriever: Node ID: ba513a34-1724-42d4-a76c-1734732701f2\n",
      "Text: After clicking REVIEW ORDER button, it turns to Review Order\n",
      "screen then click PLACE BUY/SELL ORDER button to complete. IV.2.\n",
      "Market depth Market Depth Widget shows a lot of trading information\n",
      "about a symbol, including Market Depth, Course of\n",
      "Score:  1.934\n",
      "\n",
      "retriever: Node ID: 7c818fa3-d32b-4737-aef9-0c11124a14e9\n",
      "Text: Quick Function Bar: you can export CSV files/ add a symbol to\n",
      "Favorites / add a symbol to watchlist/ place a new order III. Market\n",
      "Analysis III.1.\n",
      "Score:  1.833\n",
      "\n",
      "retriever: Node ID: dbc2135e-3f53-4378-80a7-adb5724acaf8\n",
      "Text: want to place Display if Purchase By = Value Limit Price The\n",
      "price the client would like to trigger • Display if Order type = Limit\n",
      "or Stop Limit • Allow decimal and integer Trigger Price The point at\n",
      "which your buy or sell order is transferred to exchange with the limit\n",
      "price Note: • Display if Order type = Stop Limit • Allow decimal and\n",
      "intege...\n",
      "Score:  1.640\n",
      "\n",
      "retriever: Node ID: 8ed4114a-a2e8-49a4-b597-3b7d929d9afd\n",
      "Text: Equix Technologies PTY LTD 121 King Street, Melbourne, VIC 3000,\n",
      "Australia +61 3 9068 3968 Equix Technologies Company Limited 106 Hoang\n",
      "Quoc Viet, Nghia Do, Cau Giay, Hanoi 285 Cach Mang Thang 8, Ward 12,\n",
      "District 10, HCMC +84 24 7300 8999 I. Getting started with Equix I.1.\n",
      "Score:  1.638\n",
      "\n",
      "retriever: Node ID: c744e6af-ea0b-41eb-94a3-cada74188e9c\n",
      "Text: Search Tool: Search for one specific symbol as you expect only\n",
      "by entering search conditions 2. Quick Function Bar: you can export\n",
      "CSV files/ add a symbol to Favorites / add a symbol to watchlist/\n",
      "place a new order 3.\n",
      "Score:  1.632\n",
      "\n",
      "_____________________________________\n",
      "Response from the chat engine\n",
      "To place an order, you can follow these steps:\n",
      "\n",
      "1. **Open the Widget**: You can do this by selecting the Menu and then choosing either \"New Order\" or navigating to \"Trading\" and selecting \"New Order.\"\n",
      "\n",
      "2. **Input Order Details**: \n",
      "   - You will need to enter the value of the order you want to place. \n",
      "   - If you are purchasing by value, make sure to display that option.\n",
      "   - Specify the **Limit Price**, which is the price at which you would like to trigger the order.\n",
      "   - If you are using a Stop Limit order, you will also need to enter a **Trigger Price**, which is the point at which your buy or sell order is transferred to the exchange.\n",
      "\n",
      "3. **Set Duration**: Choose the duration for your order. There are five types:\n",
      "   - **DAY**: The order will expire at the end of the trading day.\n",
      "   - **GTC (Good Till Canceled)**: The order remains active until you cancel it.\n",
      "\n",
      "4. **Review Your Order**: After entering all the necessary information, click the \"REVIEW ORDER\" button. This will take you to the Review Order screen.\n",
      "\n",
      "5. **Place the Order**: Finally, click the \"PLACE BUY/SELL ORDER\" button to complete the process.\n",
      "\n",
      "Make sure to double-check all the details before placing your order to ensure everything is correct! If you have any specific questions about the process, feel free to ask!"
     ]
    }
   ],
   "source": [
    "string = \"Hello?\"\n",
    "response = chat_agent.stream_chat(string)\n",
    "\n",
    "print(\"Retrieved nodes from the index:\")\n",
    "for i in response.source_nodes:\n",
    "   print(f\"retriever: {i}\")\n",
    "print(\"_____________________________________\")\n",
    "print(\"Response from the chat engine\")\n",
    "#response1 = query_engine.query(\"Placing an order\")\n",
    "\n",
    "for token in response.response_gen:\n",
    "   print(token, end =\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
